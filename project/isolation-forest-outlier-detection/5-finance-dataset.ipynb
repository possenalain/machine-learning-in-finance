{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "#import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, average_precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset**\n",
    "\n",
    "\n",
    "- [5-Defaulter](./data/Default.xlsx) \n",
    "```markdown\n",
    "\n",
    "Its a Finance type dataset with 10k rows and 5 columns.\n",
    "default column whether someone is defaulter or not in the data with yes and no data in that column\n",
    "similarly in Students columns we can se whether person is student or not\n",
    "there are balance and income data of the personâ€¦.\n",
    "\n",
    "```\n",
    "\n",
    "( more : https://www.kaggle.com/datasets/creepycrap/finance-dataset )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = Path('data')\n",
    "work_with = \"Default.xlsx\"\n",
    "\n",
    "df = pd.read_excel(data_dir / work_with, index_col=0)\n",
    "#Impute missing values with 0 since it means the company have no value for that year\n",
    "# df.fillna(0,inplace=True)\n",
    "df.dropna(inplace=True, axis=1, how='any')\n",
    "\n",
    "# df.describe()\n",
    "#df.info()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  default student      balance        income\n",
       "1      No      No   729.526495  44361.625074\n",
       "2      No     Yes   817.180407  12106.134700\n",
       "3      No      No  1073.549164  31767.138947\n",
       "4      No      No   529.250605  35704.493935\n",
       "5      No      No   785.655883  38463.495879"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default\n",
      "No     9667\n",
      "Yes     333\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# data distribution \n",
    "# 0 - no-fraus, 1 - fraud\n",
    "\n",
    "print(f'{df[\"default\"].value_counts()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "the default column is the target column and rest are features.\n",
    "\n",
    "we have outlier if the person is defaulter.\n",
    "default - yes - 1\n",
    "default - no - 0\n",
    "\n",
    "we can also sub-sample the outliers\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before:default\n",
      "No     9667\n",
      "Yes     333\n",
      "Name: count, dtype: int64\n",
      "After: default\n",
      "0    9667\n",
      "1     333\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# data distribution \n",
    "# 0 - increased, 1 - otherwise\n",
    "# df.drop(['isFlaggedFraud'], inplace=True, axis=1)\n",
    "\n",
    "target = 'default'\n",
    "\n",
    "print(f'before:{df[target].value_counts()}')\n",
    "\n",
    "#switch classes \n",
    "df[target] = df[target].map({\"Yes\": 1, \"No\": 0})\n",
    "print(f'After: {df[target].value_counts()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled: default\n",
      "0    9667\n",
      "1     174\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# sample non_increasing class\n",
    "inbound_df = df[df[target] == 0]\n",
    "outlier_df = df[df[target] == 1].sample(n=int(0.018*len(inbound_df)), random_state=42)\n",
    "\n",
    "df = pd.concat([inbound_df, outlier_df])\n",
    "print(f'Sampled: {df[target].value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uniques val count:\n",
      "student    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# handle categorical data\n",
    "cat_columns = df.select_dtypes(include=['object'], exclude=[\"number\"]).columns\n",
    "print(f\"uniques val count:\\n{df[[*cat_columns]].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode student \n",
    "df = pd.get_dummies(df, columns=[\"student\"], prefix=[\"ST\"],dtype=\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "      <th>ST_No</th>\n",
       "      <th>ST_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   default      balance        income  ST_No  ST_Yes\n",
       "1        0   729.526495  44361.625074      1       0\n",
       "2        0   817.180407  12106.134700      0       1\n",
       "3        0  1073.549164  31767.138947      1       0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_columns = df.select_dtypes(include=['object'], exclude=[\"number\"]).columns\n",
    "\n",
    "# # encode Unnamed: 0 and nameDest with label encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for col in cat_columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    \n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9841, 4), (9841,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = \"default\"\n",
    "\n",
    "X = df.drop([target], axis=1)\n",
    "y = df[target]\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9841, 4), (9841,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scaling the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X[X.columns] = scaler.fit_transform(X)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: \n",
      " default\n",
      "0    9667\n",
      "1     174\n",
      "Name: count, dtype: int64\n",
      "Test: \n",
      " default\n",
      "0    9667\n",
      "1     174\n",
      "Name: count, dtype: int64 \n"
     ]
    }
   ],
   "source": [
    "# split the data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "#                                                     stratify=y,\n",
    "#                                                     test_size=0.2,\n",
    "#                                                     random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = X, X, y, y\n",
    "\n",
    "\n",
    "# count fraud in train and test \n",
    "print(f\"Train: \\n {y_train.value_counts()}\")\n",
    "print(f\"Test: \\n {y_test.value_counts()} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Helper functions '''\n",
    "\n",
    "def get_scores(y_true, y_pred):\n",
    "    scores = {\n",
    "        'accuracy': round(accuracy_score(y_true, y_pred),2),\n",
    "        'balanced': round(balanced_accuracy_score(y_true, y_pred),2),\n",
    "        'F1': round(f1_score(y_true, y_pred),2),\n",
    "        'precision': round(precision_score(y_true, y_pred),2),\n",
    "        'recall': round(recall_score(y_true, y_pred),2),\n",
    "        'roc_auc': round(roc_auc_score(y_true, y_pred),2),\n",
    "        'pr_auc': round(average_precision_score(y_true, y_pred),2)\n",
    "    }\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_scores = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "isolation forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolation forest\n",
    "\n",
    "from pyod.models.iforest import IForest\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "clf_name = 'IForest'\n",
    "\n",
    "clf = IForest()\n",
    "clf.fit(X_train)\n",
    "\n",
    "duration = round(time.time() - start_time,2)\n",
    "\n",
    "# get the prediction labels and outlier scores of the training data\n",
    "y_train_pred = clf.labels_  # binary labels (0: inliers, 1: outliers)\n",
    "y_train_scores = clf.decision_scores_  # raw outlier scores\n",
    "\n",
    "# get the prediction on the test data\n",
    "y_test_pred = clf.predict(X_test)  # outlier labels (0 or 1)\n",
    "y_test_scores = clf.decision_function(X_test)  # outlier scores\n",
    "\n",
    "scores = {\"clf_name\":clf_name, **get_scores(y_test, y_test_pred), \"duration\": duration}\n",
    "combined_scores.append(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local Outlier Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Local Outlier Factor\n",
    "\n",
    "from pyod.models.lof import LOF\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "clf_name = 'LOF'\n",
    "clf = LOF()\n",
    "clf.fit(X_train)\n",
    "duration = round(time.time() - start_time,2)\n",
    "\n",
    "# get the prediction labels\n",
    "y_train_pred = clf.labels_  \n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "scores = {\"clf_name\":clf_name, **get_scores(y_test, y_test_pred), \"duration\": duration}\n",
    "combined_scores.append(scores)\n",
    "# scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ECOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ECOD\n",
    "\n",
    "from pyod.models.ecod import ECOD\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "clf_name = 'ECOD'\n",
    "clf = ECOD()\n",
    "clf.fit(X_train)\n",
    "duration = round(time.time() - start_time,2)\n",
    "\n",
    "# get the prediction labels\n",
    "y_train_pred = clf.labels_  \n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "scores = {\"clf_name\":clf_name, **get_scores(y_test, y_test_pred), \"duration\": duration}\n",
    "combined_scores.append(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local Correlation Integral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  Local Correlation Integral (LOCI)\n",
    "\n",
    "# from pyod.models.loci import LOCI\n",
    "# start_time = time.time()\n",
    "\n",
    "\n",
    "# clf_name = 'LOCI'\n",
    "# clf = LOCI()\n",
    "# clf.fit(X_train)\n",
    "# duration = round(time.time() - start_time,2)\n",
    "\n",
    "# # get the prediction labels\n",
    "# y_train_pred = clf.labels_  \n",
    "# y_test_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "# scores = {\"clf_name\":clf_name, **get_scores(y_test, y_test_pred), \"duration\": duration}\n",
    "# combined_scores.append(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSCP: Locally Selective Combination of Parallel Outlier Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  LSCP\n",
    "\n",
    "# from pyod.models.lscp import LSCP\n",
    "# from pyod.models.lof import LOF\n",
    "# start_time = time.time()\n",
    "\n",
    "\n",
    "# clf_name = 'LSCP'\n",
    "# detector_list = [LOF(), LOF()]\n",
    "# clf = LSCP(detector_list)\n",
    "# clf.fit(X_train)\n",
    "# duration = round(time.time() - start_time,2)\n",
    "\n",
    "# # get the prediction labels\n",
    "# y_train_pred = clf.labels_  \n",
    "# y_test_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "# scores = {\"clf_name\":clf_name, **get_scores(y_test, y_test_pred), \"duration\": duration}\n",
    "# combined_scores.append(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COPOD: Copula-Based Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  COPOD: Copula-Based Outlier Detection\n",
    "\n",
    "from pyod.models.copod import COPOD\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "clf_name = 'COPOD'\n",
    "clf = COPOD()\n",
    "clf.fit(X_train)\n",
    "duration = round(time.time() - start_time,2)\n",
    "\n",
    "# get the prediction labels\n",
    "y_train_pred = clf.labels_  \n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "scores = {\"clf_name\":clf_name, **get_scores(y_test, y_test_pred), \"duration\": duration}\n",
    "combined_scores.append(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ABOD: Angle-Based Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ABOD: Angle-Based Outlier Detection\n",
    "\n",
    "from pyod.models.abod import ABOD\n",
    "start_time = time.time()\n",
    "\n",
    "clf_name = 'ABOD'\n",
    "clf = ABOD()\n",
    "clf.fit(X_train)\n",
    "duration = round(time.time() - start_time,2)\n",
    "\n",
    "# get the prediction labels\n",
    "y_train_pred = clf.labels_  \n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "scores = {\"clf_name\":clf_name, **get_scores(y_test, y_test_pred), \"duration\": duration}\n",
    "combined_scores.append(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QMCD: Quasi-Monte Carlo Discrepancy outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QMCD: Quasi-Monte Carlo Discrepancy outlier detection\n",
    "\n",
    "from pyod.models.qmcd import QMCD\n",
    "start_time = time.time()\n",
    "\n",
    "clf_name = 'QMCD'\n",
    "clf = QMCD()\n",
    "clf.fit(X_train)\n",
    "duration = round(time.time() - start_time,2)\n",
    "\n",
    "# get the prediction labels\n",
    "y_train_pred = clf.labels_  \n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "scores = {\"clf_name\":clf_name, **get_scores(y_test, y_test_pred), \"duration\": duration}\n",
    "combined_scores.append(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rapid distance-based outlier detection via sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAD - Rapid distance-based outlier detection via sampling\n",
    "\n",
    "from pyod.models.sampling import Sampling\n",
    "start_time = time.time()\n",
    "\n",
    "clf_name = 'Rapid distance-based'\n",
    "clf = Sampling()\n",
    "clf.fit(X_train)\n",
    "duration = round(time.time() - start_time,2)\n",
    "\n",
    "# get the prediction labels\n",
    "y_train_pred = clf.labels_  \n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "scores = {\"clf_name\":clf_name, **get_scores(y_test, y_test_pred), \"duration\": duration}\n",
    "combined_scores.append(scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book Keeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results\n",
    "\n",
    "save_dir = Path('results')\n",
    "save_dir.mkdir(exist_ok=True)\n",
    "save_as = save_dir / f\"5-{Path(work_with).stem}.csv\"\n",
    "\n",
    "scores_df = pd.DataFrame(combined_scores)\n",
    "scores_df.to_csv(save_as, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf_name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced</th>\n",
       "      <th>F1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>pr_auc</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IForest</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LOF</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ECOD</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COPOD</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABOD</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>QMCD</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rapid distance-based</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               clf_name  accuracy  balanced    F1  precision  recall  roc_auc  \\\n",
       "0               IForest      0.90      0.72  0.16       0.09    0.53     0.72   \n",
       "1                   LOF      0.91      0.63  0.12       0.07    0.34     0.63   \n",
       "2                  ECOD      0.90      0.71  0.15       0.09    0.51     0.71   \n",
       "3                 COPOD      0.90      0.76  0.18       0.11    0.61     0.76   \n",
       "4                  ABOD      0.90      0.70  0.15       0.09    0.49     0.70   \n",
       "5                  QMCD      0.90      0.76  0.18       0.11    0.61     0.76   \n",
       "6  Rapid distance-based      0.91      0.78  0.20       0.12    0.66     0.78   \n",
       "\n",
       "   pr_auc  duration  \n",
       "0    0.06      0.28  \n",
       "1    0.04      0.07  \n",
       "2    0.05      0.31  \n",
       "3    0.07      0.01  \n",
       "4    0.05      1.61  \n",
       "5    0.07      0.86  \n",
       "6    0.08      0.01  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(scores_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` markdown\n",
    "\n",
    "# methods used\n",
    "1. [Isolation Forest](https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/icdm08b.pdf)\n",
    "2. ...\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "outlierEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
